import os
import json
import math
import io
import pandas as pd
from datetime import datetime
import requests
from google.oauth2 import service_account
from googleapiclient.discovery import build
from googleapiclient.http import MediaIoBaseDownload

# ================== ì‚¬ìš©ì ì„¤ì • (ë‹¤ì‹œ í™•ì¸í•˜ì„¸ìš”!) ==================
GDRIVE_FOLDER_ID = "10tC3MvA9gzjv1E3rdBDi6ZyMaf4lSEni"
# âš ï¸ ì£¼ì˜: í‚¤ë¥¼ ë‹¤ì‹œ ë³µì‚¬í•´ì„œ ë¶™ì—¬ë„£ì„ ë•Œ ì•ë’¤ ê³µë°±ì´ ì—†ëŠ”ì§€ ê¼­ í™•ì¸í•˜ì„¸ìš”!
NOTION_KEY = "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"
NOTION_DB_ID = "2ddb9d7d1d4a81028e19d09a1386f820"
# ===============================================================

def send_to_notion(summary):
    url = "https://api.notion.com/v1/pages"
    # í† í° ì•ë’¤ ê³µë°± ì œê±° ì²˜ë¦¬ (.strip())
    headers = {
        "Authorization": f"Bearer {NOTION_KEY.strip()}",
        "Content-Type": "application/json",
        "Notion-Version": "2022-06-28",
    }

ACCURACY_LIMIT = 50
MIN_MOVE_DISTANCE = 30  # meters
# ===============================================


def get_credentials():
    if os.path.exists("service_account.json"):
        return service_account.Credentials.from_service_account_file(
            "service_account.json",
            scopes=["https://www.googleapis.com/auth/drive.readonly"],
        )
    info = json.loads(os.environ["GDRIVE_SA_KEY"])
    return service_account.Credentials.from_service_account_info(
        info,
        scopes=["https://www.googleapis.com/auth/drive.readonly"],
    )


def haversine(lat1, lon1, lat2, lon2):
    R = 6371000
    phi1, phi2 = math.radians(lat1), math.radians(lat2)
    dphi = math.radians(lat2 - lat1)
    dl = math.radians(lon2 - lon1)
    a = math.sin(dphi / 2) ** 2 + math.cos(phi1) * math.cos(phi2) * math.sin(dl / 2) ** 2
    return 2 * R * math.atan2(math.sqrt(a), math.sqrt(1 - a))


def download_all_csv():
    creds = get_credentials()
    service = build("drive", "v3", credentials=creds)

    results = service.files().list(
        q=f"'{GDRIVE_FOLDER_ID}' in parents and trashed=false",
        fields="files(id,name,mimeType)",
        pageSize=100,
    ).execute()

    dfs = []

    for f in results.get("files", []):
        if not f["name"].lower().endswith(".csv"):
            continue

        fh = io.BytesIO()

        # ğŸ”¥ í•µì‹¬ ë¶„ê¸°
        if f["mimeType"].startswith("application/vnd.google-apps"):
            request = service.files().export_media(
                fileId=f["id"],
                mimeType="text/csv"
            )
        else:
            request = service.files().get_media(fileId=f["id"])

        downloader = MediaIoBaseDownload(fh, request)
        done = False
        while not done:
            _, done = downloader.next_chunk()

        fh.seek(0)
        dfs.append(pd.read_csv(fh))

    if not dfs:
        raise RuntimeError("âŒ CSV ë°ì´í„°ë¥¼ í•˜ë‚˜ë„ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

    return pd.concat(dfs, ignore_index=True)



def send_to_notion(summary):
    url = "https://api.notion.com/v1/pages"
    headers = {
        "Authorization": f"Bearer {NOTION_KEY}",
        "Content-Type": "application/json",
        "Notion-Version": "2022-06-28",
    }

    payload = {
        "parent": {"database_id": NOTION_DB_ID},
        "properties": {
            "ë‚ ì§œ": {"title": [{"text": {"content": summary["date"]}}]},
            "ì²´ë¥˜ ì¥ì†Œ": {
                "multi_select": [{"name": p} for p in summary["places"]]
            },
            "ì´ë™ ìš”ì•½": {
                "rich_text": [{"text": {"content": summary["route"]}}]
            },
            "ì´ ì´ë™ê±°ë¦¬(km)": {"number": round(summary["distance_km"], 2)},
            "ì´ ì´ë™ì‹œê°„(ë¶„)": {"number": summary["duration_min"]},
            "ì§€ë„ ë§í¬": {"url": summary["map_url"]},
        },
    }

    r = requests.post(url, headers=headers, json=payload)
    if r.status_code == 200:
        print(f"âœ… {summary['date']} ë“±ë¡ ì™„ë£Œ")
    else:
        print("âŒ ë…¸ì…˜ ì˜¤ë¥˜:", r.text)


def main():
    df = download_all_csv()
    df.columns = df.columns.str.lower()
    df["datetime"] = pd.to_datetime(df["time"])

    if "accuracy" in df.columns:
        df = df[df["accuracy"] <= ACCURACY_LIMIT]

    now = datetime.now()
    today = now.date()

    # ================= ë‚ ì§œ ì»· ì •ì±… =================
    if today <= datetime(2026, 1, 10).date():
        target_df = df[df["datetime"].dt.date <= today]
        print(f"ğŸ§± ì´ˆê¸° ëˆ„ì  ëª¨ë“œ (~ {today})")
    else:
        target_df = df[df["datetime"].dt.date == today]
        print(f"ğŸ“† ì¼ì¼ ëª¨ë“œ ({today})")
    # ===============================================

    target_df["date"] = target_df["datetime"].dt.date

    for date, g in target_df.groupby("date"):
        g = g.sort_values("datetime")
        if len(g) < 2:
            continue

        dist = 0
        path = [g.iloc[0]]

        for i in range(1, len(g)):
            d = haversine(
                g.iloc[i - 1].lat,
                g.iloc[i - 1].lon,
                g.iloc[i].lat,
                g.iloc[i].lon,
            )
            if d >= MIN_MOVE_DISTANCE:
                dist += d
                path.append(g.iloc[i])

        if len(path) < 2:
            continue

        duration = int(
            (g.iloc[-1].datetime - g.iloc[0].datetime).total_seconds() / 60
        )

        coords = "/".join([f"{p.lat},{p.lon}" for p in path])
        map_url = f"https://www.google.com/maps/dir/{coords}"

        summary = {
            "date": str(date),
            "places": ["ì´ë™"],
            "route": " â†’ ".join(
                [f"{p.lat:.3f},{p.lon:.3f}" for p in path[:5]]
            ),
            "distance_km": dist / 1000,
            "duration_min": duration,
            "map_url": map_url,
        }

        send_to_notion(summary)


if __name__ == "__main__":
    main()
